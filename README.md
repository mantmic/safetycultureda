# SafetyCulture Data Engineering Challenge

## Overview
This repository is for the SafetyCulture Data Engineering challenge.

Docker is used to spin up a number of services for the data pipeline.

The purpose of each service is as follows;

| Service  | Description |
| ------------- | ------------- |
| postgres  | The postgres database used for this data pipeline |
| postgres-seed  | A service that creates database tables, inserts raw customer documents and CRM data into the postgres database. This runs once when the services are started, then stops.  |

## Requirements

* docker
* docker-compose
* R (for the head-end example)

## General architecture

The following diagram shows the architecture of this data stream.

![architecture diagram](https://github.com/mantmic/safetyculturede/raw/master/src/images/diagram.png "Data architecture")


User metadata is pushed directly into the database. User events are retrieved via a message broker.

In this example, the postgres-seed service will populate the staging tables, simulating data landing in the database from a foreign system, then it will run the ETL procedure to populate the sc.sc_user table.

The user-event-seed service will push messages onto the message broker, which will be automatically processed by the user-event service and pushed into the database.

View the logs of the user-event service to see it process each individual message.
```
docker-compose logs user-event
```

The postgres database can be connected to and explored locally via port 5432.

```

```

## Running

Run the following to pull the repository, pull build the docker images, and start the services.

```
git clone https://github.com/mantmic/safetyculturede
cd safetyculturede
docker-compose build
docker-compose up -d
```



### Head-end example
To show an example on how a data analyst may connect to the database to perform some analysis, the headend-example directory contains an R script that connects to the database and generates a report.

From the repository directory this report can be generated by running
```

```



## Database structure

### Dimensions

The SafetyCulture software is used as the master system for this data warehouse. The user table in software is based on users of the SafetyCulture application ecosystem. ETLs attend to associate users from other systems (e.g. CRM) to a SafetyCulture user.

All dimensional user data (data about the user, not their real-time actions), lands in the staging schema in the database.

An ETL process integrates user data from various sources into a single table with all information on the customer, sc.sc_user.

As a user can move between companies but retain their SafetyCulture account, history must be kept so that user behaviour is associated with the correct organisation. As a result, historical changes for the customer are tracked in sc.sc_user_hist.


### Real-time customer events

As this is where most of the data volume will come from, the data will require minimal manipulation, and there may be real-time analytics requirements, user event data will be directly inserted into the sc.sc_user_event table.

### Tables

| Schema  | Table | Description |
| ------------- | ------------- |
| staging  | sc_user_document | Raw SafetyCulture user data in a NoSQL / JSON nested structure |
| staging  | crm_customer | Raw output of crm customer data |
| sc  | sc_user | User dimension containing information user/customer information extracted from multiple sources |
| sc  | sc_user_hist | Table that tracks historical changes to sc.sc_user |
| sc  | sc_user_event | Table containing real-time user event data |
